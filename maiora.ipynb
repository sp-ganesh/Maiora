{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!apt-get install -y poppler-utils\n",
        "!pip install pdfplumber pytesseract pdf2image openpyxl\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lkUJjuBTHOx_",
        "outputId": "6943723d-ee00-44da-8433-593c230af076"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  poppler-utils\n",
            "0 upgraded, 1 newly installed, 0 to remove and 49 not upgraded.\n",
            "Need to get 186 kB of archives.\n",
            "After this operation, 696 kB of additional disk space will be used.\n",
            "Ign:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 poppler-utils amd64 22.02.0-2ubuntu0.5\n",
            "Err:1 http://security.ubuntu.com/ubuntu jammy-updates/main amd64 poppler-utils amd64 22.02.0-2ubuntu0.5\n",
            "  404  Not Found [IP: 91.189.91.82 80]\n",
            "E: Failed to fetch http://security.ubuntu.com/ubuntu/pool/main/p/poppler/poppler-utils_22.02.0-2ubuntu0.5_amd64.deb  404  Not Found [IP: 91.189.91.82 80]\n",
            "E: Unable to fetch some archives, maybe run apt-get update or try with --fix-missing?\n",
            "Collecting pdfplumber\n",
            "  Downloading pdfplumber-0.11.5-py3-none-any.whl.metadata (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.5/42.5 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytesseract\n",
            "  Downloading pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting pdf2image\n",
            "  Downloading pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.10/dist-packages (3.1.5)\n",
            "Collecting pdfminer.six==20231228 (from pdfplumber)\n",
            "  Downloading pdfminer.six-20231228-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.10/dist-packages (from pdfplumber) (11.0.0)\n",
            "Collecting pypdfium2>=4.18.0 (from pdfplumber)\n",
            "  Downloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20231228->pdfplumber) (3.4.0)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20231228->pdfplumber) (43.0.3)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (24.2)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl) (2.0.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (2.22)\n",
            "Downloading pdfplumber-0.11.5-py3-none-any.whl (59 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdfminer.six-20231228-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m44.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytesseract-0.3.13-py3-none-any.whl (14 kB)\n",
            "Downloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
            "Downloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m52.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pytesseract, pypdfium2, pdf2image, pdfminer.six, pdfplumber\n",
            "Successfully installed pdf2image-1.17.0 pdfminer.six-20231228 pdfplumber-0.11.5 pypdfium2-4.30.1 pytesseract-0.3.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pdfplumber\n",
        "import pandas as pd\n",
        "import pytesseract\n",
        "from pdf2image import convert_from_path\n",
        "import openpyxl\n",
        "\n",
        "def extract_tables_from_pdf(pdf_path, page_number):\n",
        "    tables_data = []\n",
        "    with pdfplumber.open(pdf_path) as pdf:\n",
        "        page = pdf.pages[page_number - 1]\n",
        "        tables = page.extract_tables()\n",
        "\n",
        "        if not tables:\n",
        "            print(f\"No structured tables found on page {page_number}. Using OCR...\")\n",
        "            text = page.extract_text()\n",
        "            extracted_data = [[line.strip()] for line in text.split(\"\\n\") if line.strip()]\n",
        "            tables_data.append(pd.DataFrame(extracted_data))\n",
        "        else:\n",
        "            for table in tables:\n",
        "                df = pd.DataFrame(table)\n",
        "\n",
        "                df = df.applymap(lambda x: \"\\n\".join(line.strip() for line in str(x).splitlines()) if isinstance(x, str) else x)\n",
        "\n",
        "                tables_data.append(df)\n",
        "    return tables_data\n",
        "\n",
        "def perform_ocr_on_page(pdf_path, page_number):\n",
        "    images = convert_from_path(pdf_path, first_page=page_number, last_page=page_number)\n",
        "    extracted_text = []\n",
        "    for image in images:\n",
        "        text = pytesseract.image_to_string(image)\n",
        "        extracted_text.append(text)\n",
        "    return \"\\n\".join(extracted_text)\n",
        "\n",
        "pdf_files = {\n",
        "    \"cardio_structured.pdf\": 6,\n",
        "    \"prot_sap_102.pdf\": 50,\n",
        "    \"prot_sap_1.pdf\": 14\n",
        "}\n",
        "\n",
        "output_file = \"extracted_tables.xlsx\"\n",
        "writer = pd.ExcelWriter(output_file, engine='openpyxl')\n",
        "\n",
        "def adjust_column_width(sheet, dataframe):\n",
        "    for idx, col in enumerate(dataframe.columns):\n",
        "        max_length = max([len(str(val).strip()) if val else 0 for val in dataframe[col]])\n",
        "        adjusted_width = min(max_length + 2, 30)\n",
        "        sheet.column_dimensions[openpyxl.utils.get_column_letter(idx + 1)].width = adjusted_width\n",
        "\n",
        "for pdf_name, page_number in pdf_files.items():\n",
        "    print(f\"Processing {pdf_name} - Page {page_number}...\")\n",
        "    pdf_path = f\"./{pdf_name}\"\n",
        "\n",
        "    tables = extract_tables_from_pdf(pdf_path, page_number)\n",
        "\n",
        "    if tables:\n",
        "        for i, table in enumerate(tables):\n",
        "            sheet_name = f\"{pdf_name}_Page{page_number}_Table{i+1}\"[:31]\n",
        "\n",
        "            table_df = pd.DataFrame(table)\n",
        "\n",
        "            if pdf_name == \"cardio_structured.pdf\":\n",
        "                table_df = table_df.dropna(how=\"all\", axis=1)\n",
        "                table_df = table_df.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
        "\n",
        "            table_df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
        "\n",
        "            sheet = writer.sheets[sheet_name]\n",
        "            adjust_column_width(sheet, table_df)\n",
        "\n",
        "            for row in sheet.iter_rows():\n",
        "                for cell in row:\n",
        "                    cell.alignment = openpyxl.styles.Alignment(wrap_text=True, vertical=\"top\")\n",
        "    else:\n",
        "        extracted_text = perform_ocr_on_page(pdf_path, page_number)\n",
        "        df_text = pd.DataFrame([[line.strip()] for line in extracted_text.split(\"\\n\") if line.strip()])\n",
        "\n",
        "        sheet_name = f\"{pdf_name}_Page{page_number}_OCR\"[:31]\n",
        "        df_text.to_excel(writer, sheet_name=sheet_name, index=False)\n",
        "\n",
        "writer.close()\n",
        "print(f\"Extraction completed! Saved as {output_file}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CNjNmKpbHZfZ",
        "outputId": "0226ffe7-6327-42f9-ed5e-c60bca496346"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing cardio_structured.pdf - Page 6...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-528dba6d2c3d>:22: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  df = df.applymap(lambda x: \"\\n\".join(line.strip() for line in str(x).splitlines()) if isinstance(x, str) else x)\n",
            "<ipython-input-3-528dba6d2c3d>:64: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  table_df = table_df.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing prot_sap_102.pdf - Page 50...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-528dba6d2c3d>:22: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  df = df.applymap(lambda x: \"\\n\".join(line.strip() for line in str(x).splitlines()) if isinstance(x, str) else x)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing prot_sap_1.pdf - Page 14...\n",
            "Extraction completed! Saved as extracted_tables.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(output_file)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "yu5yYqN_HPR5",
        "outputId": "36a7cf63-31e9-4d40-9fa3-94530d4ac3fe"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_818e94f2-ca0d-4d1f-bad5-c835f8257149\", \"extracted_tables.xlsx\", 9077)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tsHOb37ieDzr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}